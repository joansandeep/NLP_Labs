{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03ad561",
   "metadata": {},
   "source": [
    "# Lab1: Text Processing and Regular Expression #\n",
    "## Reg.no :2448027 ##\n",
    "## Name :Joan Sandeep Larson ##\n",
    "### Q1. Installing NLTK ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b80803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\joans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.book import *\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed6310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text1: concordance for 'monstrous' ---\n",
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "# 1.Computing with Language: Texts and Words\n",
    "# Concordances\n",
    "print(\"\\n--- text1: concordance for 'monstrous' ---\")\n",
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52965302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text2: concordance for 'sensibilty' (misspelled) ---\n",
      "no matches\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- text2: concordance for 'sensibilty' (misspelled) ---\")\n",
    "text2.concordance(\"sensibilty\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e24c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text2: concordance for 'sensibility' ---\n",
      "Displaying 10 of 10 matches:\n",
      "                      [ Sense and Sensibility by Jane Austen 1811 ] CHAPTER 1 T\n",
      "rn , the excess of her sister ' s sensibility ; but by Mrs . Dashwood it was va\n",
      ", to hear him read with so little sensibility . Mama , the more I know of the w\n",
      "erable ; and he read with all the sensibility and spirit which Edward had unfor\n",
      "the ridicule so justly annexed to sensibility . Elinor was obliged , though unw\n",
      " at consolation from either . Her sensibility was potent enough ! When breakfas\n",
      "her on the delicacies of a strong sensibility , and the graces of a polished ma\n",
      " a strong impulse of affectionate sensibility , she moved after a moment , to h\n",
      "proof of her ' s , but by his own sensibility . \" We may treat it as a joke ,\" \n",
      "oor Fanny had suffered agonies of sensibility -- and he considered the existenc\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- text2: concordance for 'sensibility' ---\")\n",
    "text2.concordance(\"sensibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c47629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text3: concordance for 'lived' ---\n",
      "Displaying 25 of 38 matches:\n",
      "ay when they were created . And Adam lived an hundred and thirty years , and be\n",
      "ughters : And all the days that Adam lived were nine hundred and thirty yea and\n",
      "nd thirty yea and he died . And Seth lived an hundred and five years , and bega\n",
      "ve years , and begat Enos : And Seth lived after he begat Enos eight hundred an\n",
      "welve years : and he died . And Enos lived ninety years , and begat Cainan : An\n",
      " years , and begat Cainan : And Enos lived after he begat Cainan eight hundred \n",
      "ive years : and he died . And Cainan lived seventy years and begat Mahalaleel :\n",
      "rs and begat Mahalaleel : And Cainan lived after he begat Mahalaleel eight hund\n",
      "years : and he died . And Mahalaleel lived sixty and five years , and begat Jar\n",
      "s , and begat Jared : And Mahalaleel lived after he begat Jared eight hundred a\n",
      "and five yea and he died . And Jared lived an hundred sixty and two years , and\n",
      "o years , and he begat Eno And Jared lived after he begat Enoch eight hundred y\n",
      " and two yea and he died . And Enoch lived sixty and five years , and begat Met\n",
      " ; for God took him . And Methuselah lived an hundred eighty and seven years , \n",
      " , and begat Lamech . And Methuselah lived after he begat Lamech seven hundred \n",
      "nd nine yea and he died . And Lamech lived an hundred eighty and two years , an\n",
      "ch the LORD hath cursed . And Lamech lived after he begat Noah five hundred nin\n",
      "naan shall be his servant . And Noah lived after the flood three hundred and fi\n",
      "xad two years after the flo And Shem lived after he begat Arphaxad five hundred\n",
      "at sons and daughters . And Arphaxad lived five and thirty years , and begat Sa\n",
      "ars , and begat Salah : And Arphaxad lived after he begat Salah four hundred an\n",
      "begat sons and daughters . And Salah lived thirty years , and begat Eber : And \n",
      "y years , and begat Eber : And Salah lived after he begat Eber four hundred and\n",
      " begat sons and daughters . And Eber lived four and thirty years , and begat Pe\n",
      "y years , and begat Peleg : And Eber lived after he begat Peleg four hundred an\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- text3: concordance for 'lived' ---\")\n",
    "text3.concordance(\"lived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20d6795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text4: concordance for 'nation' ---\n",
      "Displaying 25 of 348 matches:\n",
      " to the character of an independent nation seems to have been distinguished by\n",
      "f Heaven can never be expected on a nation that disregards the eternal rules o\n",
      "first , the representatives of this nation , then consisting of little more th\n",
      ", situation , and relations of this nation and country than any which had ever\n",
      ", prosperity , and happiness of the nation I have acquired an habitual attachm\n",
      "an be no spectacle presented by any nation more pleasing , more noble , majest\n",
      "party for its own ends , not of the nation for the national good . If that sol\n",
      "tures and the people throughout the nation . On this subject it might become m\n",
      "if a personal esteem for the French nation , formed in a residence of seven ye\n",
      "f our fellow - citizens by whatever nation , and if success can not be obtaine\n",
      "y , continue His blessing upon this nation and its Government and give it all \n",
      "powers so justly inspire . A rising nation , spread over a wide and fruitful l\n",
      "ing now decided by the voice of the nation , announced according to the rules \n",
      "ars witness to the fact that a just nation is trusted on its word when recours\n",
      "e union of opinion which gives to a nation the blessing of harmony and the ben\n",
      "uil suffrage of a free and virtuous nation , would under any circumstances hav\n",
      "d spirit and united councils of the nation will be safeguards to its honor and\n",
      "iction that the war with a powerful nation , which forms so prominent a featur\n",
      "out breaking down the spirit of the nation , destroying all confidence in itse\n",
      "ed on the military resources of the nation . These resources are amply suffici\n",
      "the war to an honorable issue . Our nation is in number more than half that of\n",
      "ndividually have been happy and the nation prosperous . Under this Constitutio\n",
      "rights , and is able to protect the nation against injustice from foreign powe\n",
      " great agricultural interest of the nation prospers under its protection . Loc\n",
      "ak our Union , and demolish us as a nation . Our distance from Europe and the \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- text4: concordance for 'nation' ---\")\n",
    "text4.concordance(\"nation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69791851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text4: concordance for 'terror' ---\n",
      "Displaying 8 of 8 matches:\n",
      "menaces , by fraud or violence , by terror , intrigue , or venality , the Gove\n",
      "ameless , unreasoning , unjustified terror which paralyzes needed efforts to c\n",
      "ublic seemed frozen by a fatalistic terror , we proved that this is not true .\n",
      " to alter that uncertain balance of terror that stays the hand of mankind ' s \n",
      "eans freeing all Americans from the terror of runaway living costs . All must \n",
      "still . They fuel the fanaticism of terror . And they torment the lives of mil\n",
      "d maintain a strong defense against terror and destruction . Our children will\n",
      "k to advance their aims by inducing terror and slaughtering innocents , we say\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- text4: concordance for 'terror' ---\")\n",
    "text4.concordance(\"terror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca139623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text4: concordance for 'god' ---\n",
      "Displaying 25 of 116 matches:\n",
      "eliance on the protection of Almighty God , I shall forthwith commence the duti\n",
      "humble , acknowledged dependence upon God and His overruling providence . We ha\n",
      "great office I must humbly invoke the God of our fathers for wisdom and firmnes\n",
      "d the same Bible and pray to the same God , and each invokes His aid against th\n",
      "hat any men should dare to ask a just God ' s assistance in wringing their brea\n",
      "offenses which , in the providence of God , must needs come , but which , havin\n",
      "butes which the believers in a living God always ascribe to Him ? Fondly do we \n",
      "war may speedily pass away . Yet , if God wills that it continue until all the \n",
      "r all , with firmness in the right as God gives us to see the right , let us st\n",
      "the prayers of the nation to Almighty God in behalf of this consummation . Fell\n",
      "r , they have \" followed the light as God gave them to see the light .\" They ar\n",
      "ess their fathers and their fathers ' God that the Union was preserved , that s\n",
      "the support and blessings of Almighty God . Fellow citizens , in the presence o\n",
      "ng the power and goodness of Almighty God , who presides over the destiny of na\n",
      "expect the favor and help of Almighty God -- that He will give to me wisdom , s\n",
      " suggestion to enterprise and labor . God has placed upon our head a diadem and\n",
      "urn than the pledge I now give before God and these witnesses of unreserved and\n",
      "han human life can escape the laws of God and nature . Manifestly nothing is mo\n",
      "and invoking the guidance of Almighty God . Our faith teaches that there is no \n",
      "re is no safer reliance than upon the God of our fathers , who has so singularl\n",
      "e the direction and favor of Almighty God . I should shrink from the duties thi\n",
      " devolve upon it , and in the fear of God will \" take occasion by the hand and \n",
      " citizens and the aid of the Almighty God in the discharge of my responsible du\n",
      "our heartstrings like some air out of God ' s own presence , where justice and \n",
      " forward - looking men , to my side . God helping me , I will not fail them , i\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- text4: concordance for 'god' ---\")\n",
    "text4.concordance(\"god\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b7d6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text5: concordance for 'im' ---\n",
      "Displaying 25 of 149 matches:\n",
      "                                  now im left with this gay name :P PART hey e\n",
      "what did you but on e-bay i feel like im in the wrong room yeee haw U30 im con\n",
      "ike im in the wrong room yeee haw U30 im considering changing my nickname to \"\n",
      " the hell outta my freaking PM box .. Im with my fiance !!!!!!!!!!!!!!!! answe\n",
      "m impressed . PART hiya room lmao !!! im doin alright thanks omg Finger .. Dee\n",
      "th lol JOIN so read it . thanks U7 .. Im happy to have my fiance here !! forwa\n",
      "i didnt me phone you . . . sheesh now im that phone perv guy lets hope not U12\n",
      "to spain ? i need to go this summer . im a HUGE phone perv ok seriously who wa\n",
      "an ... . ACTION video tapes . hey U20 Im blind now . ACTION has left the room \n",
      "T u got that right , i dont do shit , im the supervisor Hello U165 . hey U165 \n",
      " him in the \" untouchable \" list U115 im good U6 lmao U7 how r u U128 hehe how\n",
      "can I ask where ya all are from ..... im here in kentucky as I said ... too wi\n",
      "ic but had to resize and stuff U37 no im an equal oppertunity hater LOL Hi , U\n",
      "he cover weeeeeeeee thanks U19 ! PART im out in cal now U3 looking at some new\n",
      " :) hi U58 lol wb U29 hi U29 U13 .... im down to time now PART Hello U24 , wel\n",
      ", I 'd never kick you outta my box hi im good thanks U16 yerself ?? PART inter\n",
      "ke wth . . who are you even ty U34 yw Im glad he 's back . awwww U16 i like ps\n",
      " ha U23 !!! wow ... are you the U39 ? Im talkin about all yer typin . . It 's \n",
      "... you ??? Apparently , I 'm not U41 im good U23 dear . How are you U23 ~wink\n",
      "~ U35 ... I love that 5 am phone call im good ... me and eric r back together \n",
      " , I am happy . You know i LuverZ YOU im the same busy busy oh ok then U1 nm l\n",
      "))) . ACTION stretches . ty U19 Ugh , Im so sore ! Repeatedly , with a big sti\n",
      "'m a size queen U41 Why U45 ? naw U23 im cheating on you with Jayse hes hawt t\n",
      "oeer is sum1 gonna ghet fuked up ? :) im always hungry yeah U45 .. i believe i\n",
      "without first asking permission . U35 im sorry U35 i tried to refrain me too U\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- text5: concordance for 'im' ---\")\n",
    "text5.concordance(\"im\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857c977f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text5: concordance for 'ur' ---\n",
      "Displaying 21 of 21 matches:\n",
      "k up PART no i dont want daughters !! ur annoying . ACTION Now Playing - Cradl\n",
      "ooo U92 !!!!!! . ACTION U1370 watches ur nad with a stick . ca u U23 ewwww lol\n",
      "er lip . Meep . ACTION is resisting . ur female right lol U115 beeeeehave Reme\n",
      " geeshh ... two kids fighting ! whats ur major i probably sucks in summer too \n",
      "II Men scorpions rock ... lol what is ur job me too U11 hehe went to manhattan\n",
      "e no one i like to say if u have done ur time then that is that U42 Ok U37 , i\n",
      "hat a ride JOIN ty ty cheers babes .. ur the first to follow up with the pseud\n",
      " charger \\ty LoL yeah ;-) well i hope ur doing ok .. i 'm dojn fine babe . . g\n",
      " gonna rock up soojn and rob u of all ur ' candy ' :) as long as you are happy\n",
      "genital warts ? LoL moped U28 ?.. ohh ur a real man i had a moped once yup heh\n",
      "b-day is in 5 days =( PART LOL U35 no ur nawt yup your gay lmao U37 dang come \n",
      " people talk to me anymore oh because ur gay . PART PART . ACTION = U58 . Man \n",
      " om hi U73 heya U7 ! h shit i get all ur money now fawker ok girl lol JOIN ed \n",
      "hat tired huh U66 ? lol U75 ... bring ur pillow get comfy U70 yep , off to bed\n",
      "talked to hi sean . ACTION whispers : ur a douche . who PART . ACTION whispers\n",
      "ew england usa ? U7 .. it adds wax to ur clothes .. u think cottons breathe ?.\n",
      "ver knew what flavor to get specially ur towels lol U31 < whistles > U34 U39 I\n",
      "cks out U7 s pic JOIN PART U41 Hi U41 ur gettin pretty savvy there U39 ahhh ..\n",
      "om ? brb U30 a week .. heck a day and ur problem there , U30 ??? Hi U34 hartfo\n",
      " JOIN U57 Whats really good room JOIN ur telllin me hey any uk girls her ? JOI\n",
      "JOIN PART JOIN JOIN yea guitar rocker ur kool u lil guitar rocker PART whats e\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- text5: concordance for 'ur' ---\")\n",
    "text5.concordance(\"ur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5eedcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text5: concordance for 'lol' ---\n",
      "Displaying 25 of 822 matches:\n",
      "ast PART 24 / m boo . 26 / m and sexy lol U115 boo . JOIN PART he drew a girl w\n",
      "ope he didnt draw a penis PART ewwwww lol & a head between her legs JOIN JOIN s\n",
      "a bowl i got a blunt an a bong ...... lol JOIN well , glad it worked out my cha\n",
      "e \" PART Hi U121 in ny . ACTION would lol @ U121 . . . but appearently she does\n",
      "30 make sure u buy a nice ring for U6 lol U7 Hi U115 . ACTION isnt falling for \n",
      " didnt ya hear !!!! PART JOIN geeshhh lol U6 PART hes deaf ppl here dont get it\n",
      "es nobody here i wanna misbeahve with lol JOIN so read it . thanks U7 .. Im hap\n",
      "ies want to chat can i talk to him !! lol U121 !!! forwards too lol JOIN ALL PE\n",
      "k to him !! lol U121 !!! forwards too lol JOIN ALL PErvs ... redirect to U121 '\n",
      " loves ME the most i love myself JOIN lol U44 how do u know that what ? jerkett\n",
      "ng wrong ... i can see it in his eyes lol U20 = fiance Jerketts lmao wtf yah I \n",
      "cooler by the minute what 'd I miss ? lol noo there too much work ! why not ?? \n",
      " that mean I want you ? U6 hello room lol U83 and this .. has been the grammar \n",
      " the rule he 's in PM land now though lol ah ok i wont bug em then someone wann\n",
      "flight to hell :) lmao bbl maybe PART LOL lol U7 it was me , U83 hahah U83 ! 80\n",
      "ht to hell :) lmao bbl maybe PART LOL lol U7 it was me , U83 hahah U83 ! 808265\n",
      "082653953 K-Fed got his ass kicked .. Lol . ACTION laughs . i got a first class\n",
      " . i got a first class ticket to hell lol U7 JOIN any texas girls in here ? any\n",
      " . whats up U155 i was only kidding . lol he 's a douchebag . Poor U121 i 'm bo\n",
      " ??? sits with U30 Cum to my shower . lol U121 . ACTION U1370 watches his nads \n",
      " ur nad with a stick . ca u U23 ewwww lol *sniffs* ewwwwww PART U115 ! owww spl\n",
      "ACTION is resisting . ur female right lol U115 beeeeehave Remember the LAst tim\n",
      "pm's me . charge that is 1.99 / min . lol @ innocent hahah lol .... yeah LOLOLO\n",
      " is 1.99 / min . lol @ innocent hahah lol .... yeah LOLOLOLLL U12 thats not nic\n",
      "s . lmao no U115 Check my record . :) Lol lick em U7 U23 how old r u lol Way to\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- text5: concordance for 'lol' ---\")\n",
    "text5.concordance(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b93e1c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text1: similar to 'monstrous' ---\n",
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n",
      "\n",
      "--- text2: similar to 'monstrous' ---\n",
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n",
      "\n",
      "--- text4: similar to 'god' ---\n",
      "america freedom us war which power it all liberty justice congress\n",
      "peace law man life people government you opinion me\n"
     ]
    }
   ],
   "source": [
    "# Similar words\n",
    "print(\"\\n--- text1: similar to 'monstrous' ---\")\n",
    "text1.similar(\"monstrous\")\n",
    "\n",
    "print(\"\\n--- text2: similar to 'monstrous' ---\")\n",
    "text2.similar(\"monstrous\")\n",
    "\n",
    "print(\"\\n--- text4: similar to 'god' ---\")\n",
    "text4.similar(\"god\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d97dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text2: common contexts for 'monstrous' and 'very' ---\n",
      "am_glad a_pretty a_lucky is_pretty be_glad\n",
      "\n",
      "--- text4: common contexts for 'god' and 'war' ---\n",
      "of_and the_of of_we of_s of_in of_may of_is the_who of_they of_but\n"
     ]
    }
   ],
   "source": [
    "# Common contexts\n",
    "print(\"\\n--- text2: common contexts for 'monstrous' and 'very' ---\")\n",
    "text2.common_contexts([\"monstrous\", \"very\"])\n",
    "\n",
    "print(\"\\n--- text4: common contexts for 'god' and 'war' ---\")\n",
    "text4.common_contexts([\"god\", \"war\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f1dabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- text4: dispersion plot for political words ---\n"
     ]
    }
   ],
   "source": [
    "# Dispersion plot\n",
    "print(\"\\n--- text4: dispersion plot for political words ---\")\n",
    "\n",
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac3d353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating random text from text3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building ngram index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laid by her , and said unto Cain , Where art thou , and said , Go to ,\n",
      "I will not do it for ten ' s sons ; we dreamed each man according to\n",
      "their generatio the firstborn said unto Laban , Because I said , Nay ,\n",
      "but Sarah shall her name be . , duke Elah , duke Shobal , and Akan .\n",
      "and looked upon my affliction . Bashemath Ishmael ' s blood , but Isra\n",
      "for as a prince hast thou found of all the cattle in the valley , and\n",
      "the wo The\n",
      "\n",
      "--- number of characters in text3: ---\n",
      " 44764\n",
      "\n",
      "--- number of vocabulary items of text3: ---\n",
      " ['!', \"'\", '(', ')', ',', ',)', '.', '.)', ':', ';', ';)', '?', '?)', 'A', 'Abel', 'Abelmizraim', 'Abidah', 'Abide', 'Abimael', 'Abimelech', 'Abr', 'Abrah', 'Abraham', 'Abram', 'Accad', 'Achbor', 'Adah', 'Adam', 'Adbeel', 'Admah', 'Adullamite', 'After', 'Aholibamah', 'Ahuzzath', 'Ajah', 'Akan', 'All', 'Allonbachuth', 'Almighty', 'Almodad', 'Also', 'Alvah', 'Alvan', 'Am', 'Amal', 'Amalek', 'Amalekites', 'Ammon', 'Amorite', 'Amorites', 'Amraphel', 'An', 'Anah', 'Anamim', 'And', 'Aner', 'Angel', 'Appoint', 'Aram', 'Aran', 'Ararat', 'Arbah', 'Ard', 'Are', 'Areli', 'Arioch', 'Arise', 'Arkite', 'Arodi', 'Arphaxad', 'Art', 'Arvadite', 'As', 'Asenath', 'Ashbel', 'Asher', 'Ashkenaz', 'Ashteroth', 'Ask', 'Asshur', 'Asshurim', 'Assyr', 'Assyria', 'At', 'Atad', 'Avith', 'Baalhanan', 'Babel', 'Bashemath', 'Be', 'Because', 'Becher', 'Bedad', 'Beeri', 'Beerlahairoi', 'Beersheba', 'Behold', 'Bela', 'Belah', 'Benam', 'Benjamin', 'Beno', 'Beor', 'Bera', 'Bered', 'Beriah', 'Bethel', 'Bethlehem', 'Bethuel', 'Beware', 'Bilhah', 'Bilhan', 'Binding', 'Birsha', 'Bless', 'Blessed', 'Both', 'Bow', 'Bozrah', 'Bring', 'But', 'Buz', 'By', 'Cain', 'Cainan', 'Calah', 'Calneh', 'Can', 'Cana', 'Canaan', 'Canaanite', 'Canaanites', 'Canaanitish', 'Caphtorim', 'Carmi', 'Casluhim', 'Cast', 'Cause', 'Chaldees', 'Chedorlaomer', 'Cheran', 'Cherubims', 'Chesed', 'Chezib', 'Come', 'Cursed', 'Cush', 'Damascus', 'Dan', 'Day', 'Deborah', 'Dedan', 'Deliver', 'Diklah', 'Din', 'Dinah', 'Dinhabah', 'Discern', 'Dishan', 'Dishon', 'Do', 'Dodanim', 'Dothan', 'Drink', 'Duke', 'Dumah', 'Earth', 'Ebal', 'Eber', 'Edar', 'Eden', 'Edom', 'Edomites', 'Egy', 'Egypt', 'Egyptia', 'Egyptian', 'Egyptians', 'Ehi', 'Elah', 'Elam', 'Elbethel', 'Eldaah', 'EleloheIsrael', 'Eliezer', 'Eliphaz', 'Elishah', 'Ellasar', 'Elon', 'Elparan', 'Emins', 'En', 'Enmishpat', 'Eno', 'Enoch', 'Enos', 'Ephah', 'Epher', 'Ephra', 'Ephraim', 'Ephrath', 'Ephron', 'Er', 'Erech', 'Eri', 'Es', 'Esau', 'Escape', 'Esek', 'Eshban', 'Eshcol', 'Ethiopia', 'Euphrat', 'Euphrates', 'Eve', 'Even', 'Every', 'Except', 'Ezbon', 'Ezer', 'Fear', 'Feed', 'Fifteen', 'Fill', 'For', 'Forasmuch', 'Forgive', 'From', 'Fulfil', 'G', 'Gad', 'Gaham', 'Galeed', 'Gatam', 'Gather', 'Gaza', 'Gentiles', 'Gera', 'Gerar', 'Gershon', 'Get', 'Gether', 'Gihon', 'Gilead', 'Girgashites', 'Girgasite', 'Give', 'Go', 'God', 'Gomer', 'Gomorrah', 'Goshen', 'Guni', 'Hadad', 'Hadar', 'Hadoram', 'Hagar', 'Haggi', 'Hai', 'Ham', 'Hamathite', 'Hamor', 'Hamul', 'Hanoch', 'Happy', 'Haran', 'Hast', 'Haste', 'Have', 'Havilah', 'Hazarmaveth', 'Hazezontamar', 'Hazo', 'He', 'Hear', 'Heaven', 'Heber', 'Hebrew', 'Hebrews', 'Hebron', 'Hemam', 'Hemdan', 'Here', 'Hereby', 'Heth', 'Hezron', 'Hiddekel', 'Hinder', 'Hirah', 'His', 'Hitti', 'Hittite', 'Hittites', 'Hivite', 'Hobah', 'Hori', 'Horite', 'Horites', 'How', 'Hul', 'Huppim', 'Husham', 'Hushim', 'Huz', 'I', 'If', 'In', 'Irad', 'Iram', 'Is', 'Isa', 'Isaac', 'Iscah', 'Ishbak', 'Ishmael', 'Ishmeelites', 'Ishuah', 'Isra', 'Israel', 'Issachar', 'Isui', 'It', 'Ithran', 'Jaalam', 'Jabal', 'Jabbok', 'Jac', 'Jachin', 'Jacob', 'Jahleel', 'Jahzeel', 'Jamin', 'Japhe', 'Japheth', 'Jared', 'Javan', 'Jebusite', 'Jebusites', 'Jegarsahadutha', 'Jehovahjireh', 'Jemuel', 'Jerah', 'Jetheth', 'Jetur', 'Jeush', 'Jezer', 'Jidlaph', 'Jimnah', 'Job', 'Jobab', 'Jokshan', 'Joktan', 'Jordan', 'Joseph', 'Jubal', 'Judah', 'Judge', 'Judith', 'Kadesh', 'Kadmonites', 'Karnaim', 'Kedar', 'Kedemah', 'Kemuel', 'Kenaz', 'Kenites', 'Kenizzites', 'Keturah', 'Kiriathaim', 'Kirjatharba', 'Kittim', 'Know', 'Kohath', 'Kor', 'Korah', 'LO', 'LORD', 'Laban', 'Lahairoi', 'Lamech', 'Lasha', 'Lay', 'Leah', 'Lehabim', 'Lest', 'Let', 'Letushim', 'Leummim', 'Levi', 'Lie', 'Lift', 'Lo', 'Look', 'Lot', 'Lotan', 'Lud', 'Ludim', 'Luz', 'Maachah', 'Machir', 'Machpelah', 'Madai', 'Magdiel', 'Magog', 'Mahalaleel', 'Mahalath', 'Mahanaim', 'Make', 'Malchiel', 'Male', 'Mam', 'Mamre', 'Man', 'Manahath', 'Manass', 'Manasseh', 'Mash', 'Masrekah', 'Massa', 'Matred', 'Me', 'Medan', 'Mehetabel', 'Mehujael', 'Melchizedek', 'Merari', 'Mesha', 'Meshech', 'Mesopotamia', 'Methusa', 'Methusael', 'Methuselah', 'Mezahab', 'Mibsam', 'Mibzar', 'Midian', 'Midianites', 'Milcah', 'Mishma', 'Mizpah', 'Mizraim', 'Mizz', 'Moab', 'Moabites', 'Moreh', 'Moreover', 'Moriah', 'Muppim', 'My', 'Naamah', 'Naaman', 'Nahath', 'Nahor', 'Naphish', 'Naphtali', 'Naphtuhim', 'Nay', 'Nebajoth', 'Neither', 'Night', 'Nimrod', 'Nineveh', 'Noah', 'Nod', 'Not', 'Now', 'O', 'Obal', 'Of', 'Oh', 'Ohad', 'Omar', 'On', 'Onam', 'Onan', 'Only', 'Ophir', 'Our', 'Out', 'Padan', 'Padanaram', 'Paran', 'Pass', 'Pathrusim', 'Pau', 'Peace', 'Peleg', 'Peniel', 'Penuel', 'Peradventure', 'Perizzit', 'Perizzite', 'Perizzites', 'Phallu', 'Phara', 'Pharaoh', 'Pharez', 'Phichol', 'Philistim', 'Philistines', 'Phut', 'Phuvah', 'Pildash', 'Pinon', 'Pison', 'Potiphar', 'Potipherah', 'Put', 'Raamah', 'Rachel', 'Rameses', 'Rebek', 'Rebekah', 'Rehoboth', 'Remain', 'Rephaims', 'Resen', 'Return', 'Reu', 'Reub', 'Reuben', 'Reuel', 'Reumah', 'Riphath', 'Rosh', 'Sabtah', 'Sabtech', 'Said', 'Salah', 'Salem', 'Samlah', 'Sarah', 'Sarai', 'Saul', 'Save', 'Say', 'Se', 'Seba', 'See', 'Seeing', 'Seir', 'Sell', 'Send', 'Sephar', 'Serah', 'Sered', 'Serug', 'Set', 'Seth', 'Shalem', 'Shall', 'Shalt', 'Shammah', 'Shaul', 'Shaveh', 'She', 'Sheba', 'Shebah', 'Shechem', 'Shed', 'Shel', 'Shelah', 'Sheleph', 'Shem', 'Shemeber', 'Shepho', 'Shillem', 'Shiloh', 'Shimron', 'Shinab', 'Shinar', 'Shobal', 'Should', 'Shuah', 'Shuni', 'Shur', 'Sichem', 'Siddim', 'Sidon', 'Simeon', 'Sinite', 'Sitnah', 'Slay', 'So', 'Sod', 'Sodom', 'Sojourn', 'Some', 'Spake', 'Speak', 'Spirit', 'Stand', 'Succoth', 'Surely', 'Swear', 'Syrian', 'Take', 'Tamar', 'Tarshish', 'Tebah', 'Tell', 'Tema', 'Teman', 'Temani', 'Terah', 'Thahash', 'That', 'The', 'Then', 'There', 'Therefore', 'These', 'They', 'Thirty', 'This', 'Thorns', 'Thou', 'Thus', 'Thy', 'Tidal', 'Timna', 'Timnah', 'Timnath', 'Tiras', 'To', 'Togarmah', 'Tola', 'Tubal', 'Tubalcain', 'Twelve', 'Two', 'Unstable', 'Until', 'Unto', 'Up', 'Upon', 'Ur', 'Uz', 'Uzal', 'We', 'What', 'When', 'Whence', 'Where', 'Whereas', 'Wherefore', 'Which', 'While', 'Who', 'Whose', 'Whoso', 'Why', 'Wilt', 'With', 'Woman', 'Ye', 'Yea', 'Yet', 'Zaavan', 'Zaphnathpaaneah', 'Zar', 'Zarah', 'Zeboiim', 'Zeboim', 'Zebul', 'Zebulun', 'Zemarite', 'Zepho', 'Zerah', 'Zibeon', 'Zidon', 'Zillah', 'Zilpah', 'Zimran', 'Ziphion', 'Zo', 'Zoar', 'Zohar', 'Zuzims', 'a', 'abated', 'abide', 'able', 'abode', 'abomination', 'about', 'above', 'abroad', 'absent', 'abundantly', 'accept', 'accepted', 'according', 'acknowledged', 'activity', 'add', 'adder', 'afar', 'afflict', 'affliction', 'afraid', 'after', 'afterward', 'afterwards', 'aga', 'again', 'against', 'age', 'aileth', 'air', 'al', 'alive', 'all', 'almon', 'alo', 'alone', 'aloud', 'also', 'altar', 'altogether', 'always', 'am', 'among', 'amongst', 'an', 'and', 'angel', 'angels', 'anger', 'angry', 'anguish', 'anointedst', 'anoth', 'another', 'answer', 'answered', 'any', 'anything', 'appe', 'appear', 'appeared', 'appease', 'appoint', 'appointed', 'aprons', 'archer', 'archers', 'are', 'arise', 'ark', 'armed', 'arms', 'army', 'arose', 'arrayed', 'art', 'artificer', 'as', 'ascending', 'ash', 'ashamed', 'ask', 'asked', 'asketh', 'ass', 'assembly', 'asses', 'assigned', 'asswaged', 'at', 'attained', 'audience', 'avenged', 'aw', 'awaked', 'away', 'awoke', 'back', 'backward', 'bad', 'bade', 'badest', 'badne', 'bak', 'bake', 'bakemeats', 'baker', 'bakers', 'balm', 'bands', 'bank', 'bare', 'barr', 'barren', 'basket', 'baskets', 'battle', 'bdellium', 'be', 'bear', 'beari', 'bearing', 'beast', 'beasts', 'beautiful', 'became', 'because', 'become', 'bed', 'been', 'befall', 'befell', 'before', 'began', 'begat', 'beget', 'begettest', 'begin', 'beginning', 'begotten', 'beguiled', 'beheld', 'behind', 'behold', 'being', 'believed', 'belly', 'belong', 'beneath', 'bereaved', 'beside', 'besides', 'besought', 'best', 'betimes', 'better', 'between', 'betwixt', 'beyond', 'binding', 'bird', 'birds', 'birthday', 'birthright', 'biteth', 'bitter', 'blame', 'blameless', 'blasted', 'bless', 'blessed', 'blesseth', 'blessi', 'blessing', 'blessings', 'blindness', 'blood', 'blossoms', 'bodies', 'boldly', 'bondman', 'bondmen', 'bondwoman', 'bone', 'bones', 'book', 'booths', 'border', 'borders', 'born', 'bosom', 'both', 'bottle', 'bou', 'boug', 'bough', 'bought', 'bound', 'bow', 'bowed', 'bowels', 'bowing', 'boys', 'bracelets', 'branches', 'brass', 'bre', 'breach', 'bread', 'breadth', 'break', 'breaketh', 'breaking', 'breasts', 'breath', 'breathed', 'breed', 'brethren', 'brick', 'brimstone', 'bring', 'brink', 'broken', 'brook', 'broth', 'brother', 'brought', 'brown', 'bruise', 'budded', 'build', 'builded', 'built', 'bulls', 'bundle', 'bundles', 'burdens', 'buried', 'burn', 'burning', 'burnt', 'bury', 'buryingplace', 'business', 'but', 'butler', 'butlers', 'butlership', 'butter', 'buy', 'by', 'cakes', 'calf', 'call', 'called', 'came', 'camel', 'camels', 'camest', 'can', 'cannot', 'canst', 'captain', 'captive', 'captives', 'carcases', 'carried', 'carry', 'cast', 'castles', 'catt', 'cattle', 'caught', 'cause', 'caused', 'cave', 'cease', 'ceased', 'certain', 'certainly', 'chain', 'chamber', 'change', 'changed', 'changes', 'charge', 'charged', 'chariot', 'chariots', 'chesnut', 'chi', 'chief', 'child', 'childless', 'childr', 'children', 'chode', 'choice', 'chose', 'circumcis', 'circumcise', 'circumcised', 'citi', 'cities', 'city', 'clave', 'clean', 'clear', 'cleave', 'clo', 'closed', 'clothed', 'clothes', 'cloud', 'clusters', 'co', 'coat', 'coats', 'coffin', 'cold', 'colours', 'colt', 'colts', 'come', 'comest', 'cometh', 'comfort', 'comforted', 'comi', 'coming', 'command', 'commanded', 'commanding', 'commandment', 'commandments', 'commended', 'committed', 'commune', 'communed', 'communing', 'company', 'compassed', 'compasseth', 'conceal', 'conceive', 'conceived', 'conception', 'concerning', 'concubi', 'concubine', 'concubines', 'confederate', 'confound', 'consent', 'conspired', 'consume', 'consumed', 'content', 'continually', 'continued', 'cool', 'corn', 'corrupt', 'corrupted', 'couch', 'couched', 'couching', 'could', 'counted', 'countenance', 'countries', 'country', 'covenant', 'covered', 'covering', 'created', 'creature', 'creepeth', 'creeping', 'cried', 'crieth', 'crown', 'cru', 'cruelty', 'cry', 'cubit', 'cubits', 'cunning', 'cup', 'current', 'curse', 'cursed', 'curseth', 'custom', 'cut', 'd', 'da', 'dainties', 'dale', 'damsel', 'damsels', 'dark', 'darkne', 'darkness', 'daughers', 'daught', 'daughte', 'daughter', 'daughters', 'day', 'days', 'dea', 'dead', 'deal', 'dealt', 'dearth', 'death', 'deceitfully', 'deceived', 'deceiver', 'declare', 'decreased', 'deed', 'deeds', 'deep', 'deferred', 'defiled', 'defiledst', 'delight', 'deliver', 'deliverance', 'delivered', 'denied', 'depart', 'departed', 'departing', 'deprived', 'descending', 'desire', 'desired', 'desolate', 'despised', 'destitute', 'destroy', 'destroyed', 'devour', 'devoured', 'dew', 'did', 'didst', 'die', 'died', 'digged', 'dignity', 'dim', 'dine', 'dipped', 'direct', 'discern', 'discerned', 'discreet', 'displease', 'displeased', 'distress', 'distressed', 'divide', 'divided', 'divine', 'divineth', 'do', 'doe', 'doer', 'doest', 'doeth', 'doing', 'dominion', 'done', 'door', 'dost', 'doth', 'double', 'doubled', 'doubt', 'dove', 'down', 'dowry', 'drank', 'draw', 'dread', 'dreadful', 'dream', 'dreamed', 'dreamer', 'dreams', 'dress', 'dressed', 'drew', 'dried', 'drink', 'drinketh', 'drinking', 'driven', 'drought', 'drove', 'droves', 'drunken', 'dry', 'duke', 'dukes', 'dunge', 'dungeon', 'dust', 'dwe', 'dwell', 'dwelled', 'dwelling', 'dwelt', 'e', 'ea', 'each', 'ear', 'earing', 'early', 'earring', 'earrings', 'ears', 'earth', 'east', 'eastward', 'eat', 'eaten', 'eatest', 'edge', 'eight', 'eighteen', 'eighty', 'either', 'elder', 'elders', 'eldest', 'eleven', 'else', 'embalm', 'embalmed', 'embraced', 'emptied', 'empty', 'end', 'ended', 'endued', 'endure', 'enemies', 'enlarge', 'enmity', 'enough', 'enquire', 'enter', 'entered', 'entreated', 'envied', 'erected', 'errand', 'escape', 'escaped', 'espied', 'establish', 'established', 'ev', 'even', 'evening', 'eventide', 'ever', 'everlasting', 'every', 'evil', 'ewe', 'ewes', 'exceeding', 'exceedingly', 'excel', 'excellency', 'except', 'exchange', 'experience', 'ey', 'eyed', 'eyes', 'fa', 'face', 'faces', 'fai', 'fail', 'failed', 'faileth', 'fainted', 'fair', 'fall', 'fallen', 'falsely', 'fame', 'families', 'famine', 'famished', 'far', 'fashion', 'fast', 'fat', 'fatfleshed', 'fath', 'fathe', 'father', 'fathers', 'fatness', 'faults', 'favour', 'favoured', 'fear', 'feared', 'fearest', 'feast', 'fed', 'feeble', 'feebler', 'feed', 'feeding', 'feel', 'feet', 'fell', 'fellow', 'felt', 'fema', 'female', 'fetch', 'fetched', 'fetcht', 'few', 'fie', 'field', 'fierce', 'fifteen', 'fifth', 'fifty', 'fig', 'fill', 'filled', 'find', 'findest', 'findeth', 'finding', 'fine', 'finish', 'finished', 'fir', 'fire', 'firmame', 'firmament', 'first', 'firstborn', 'firstlings', 'fish', 'fishes', 'five', 'flaming', 'fle', 'fled', 'fleddest', 'flee', 'flesh', 'flo', 'floc', 'flock', 'flocks', 'flood', 'floor', 'fly', 'fo', 'foal', 'foals', 'folk', 'follow', 'followed', 'following', 'folly', 'food', 'foolishly', 'foot', 'for', 'forbid', 'force', 'ford', 'foremost', 'foreskin', 'forgat', 'forget', 'forgive', 'forgotten', 'form', 'formed', 'former', 'forth', 'forty', 'forward', 'fou', 'found', 'fountain', 'fountains', 'four', 'fourscore', 'fourteen', 'fourteenth', 'fourth', 'fowl', 'fowls', 'freely', 'friend', 'friends', 'fro', 'from', 'frost', 'fruit', 'fruitful', 'fruits', 'fugitive', 'fulfilled', 'full', 'furnace', 'furniture', 'fury', 'gard', 'garden', 'garmen', 'garment', 'garments', 'gat', 'gate', 'gather', 'gathered', 'gathering', 'gave', 'gavest', 'generatio', 'generation', 'generations', 'get', 'getting', 'ghost', 'giants', 'gift', 'gifts', 'give', 'given', 'giveth', 'giving', 'glory', 'go', 'goa', 'goat', 'goats', 'gods', 'goest', 'goeth', 'going', 'gold', 'golden', 'gone', 'good', 'goodly', 'goods', 'gopher', 'got', 'gotten', 'governor', 'gr', 'grace', 'gracious', 'graciously', 'grap', 'grapes', 'grass', 'grave', 'gray', 'gre', 'great', 'greater', 'greatly', 'green', 'grew', 'grief', 'grieved', 'grievous', 'grisl', 'grisled', 'gro', 'ground', 'grove', 'grow', 'grown', 'guard', 'guiding', 'guiltiness', 'guilty', 'gutters', 'h', 'ha', 'habitations', 'had', 'hadst', 'hairs', 'hairy', 'half', 'halted', 'han', 'hand', 'handfuls', 'handle', 'handmaid', 'handmaidens', 'handmaids', 'hands', 'hang', 'hanged', 'hard', 'hardly', 'harlot', 'harm', 'harp', 'harvest', 'hast', 'haste', 'hasted', 'hastened', 'hastily', 'hate', 'hated', 'hath', 'have', 'haven', 'having', 'hazel', 'he', 'head', 'heads', 'healed', 'health', 'heap', 'hear', 'heard', 'hearken', 'hearkened', 'heart', 'hearth', 'hearts', 'heat', 'heav', 'heaven', 'heavens', 'heed', 'heel', 'heels', 'heifer', 'height', 'heir', 'held', 'help', 'hence', 'henceforth', 'her', 'herb', 'herd', 'herdmen', 'herds', 'here', 'herein', 'herself', 'hid', 'hide', 'high', 'hil', 'hills', 'him', 'himself', 'hind', 'hindermost', 'hire', 'hired', 'his', 'hith', 'hither', 'hold', 'hollow', 'home', 'honey', 'honour', 'honourable', 'hor', 'horror', 'horse', 'horsemen', 'horses', 'host', 'hotly', 'hou', 'hous', 'house', 'household', 'households', 'how', 'hundred', 'hundredfo', 'hundredth', 'hunt', 'hunter', 'hunting', 'hurt', 'husba', 'husband', 'husbandman', 'if', 'ill', 'image', 'images', 'imagination', 'imagined', 'in', 'increase', 'increased', 'indeed', 'inhabitants', 'inhabited', 'inherit', 'inheritance', 'iniquity', 'inn', 'innocency', 'instead', 'instructor', 'instruments', 'integrity', 'interpret', 'interpretation', 'interpretations', 'interpreted', 'interpreter', 'into', 'intreat', 'intreated', 'ir', 'is', 'isles', 'issue', 'it', 'itself', 'jewels', 'joined', 'joint', 'journey', 'journeyed', 'journeys', 'jud', 'judge', 'judged', 'judgment', 'just', 'justice', 'keep', 'keeper', 'kept', 'ki', 'kid', 'kids', 'kill', 'killed', 'kind', 'kindled', 'kindly', 'kindness', 'kindred', 'kinds', 'kine', 'king', 'kingdom', 'kings', 'kiss', 'kissed', 'kn', 'knead', 'kneel', 'knees', 'knew', 'knife', 'know', 'knowest', 'knoweth', 'knowing', 'knowledge', 'known', 'la', 'labour', 'lack', 'lad', 'ladder', 'lade', 'laded', 'laden', 'lads', 'laid', 'lamb', 'lambs', 'lamentati', 'lamp', 'lan', 'land', 'lands', 'language', 'large', 'last', 'laugh', 'laughed', 'law', 'lawgiver', 'laws', 'lay', 'lead', 'leaf', 'lean', 'leanfleshed', 'leap', 'leaped', 'learned', 'least', 'leave', 'leaves', 'led', 'left', 'length', 'lentiles', 'lesser', 'lest', 'let', 'li', 'lie', 'lien', 'liest', 'lieth', 'life', 'lift', 'lifted', 'light', 'lighted', 'lightly', 'lights', 'like', 'likene', 'likeness', 'linen', 'lingered', 'lion', 'little', 'live', 'lived', 'lives', 'liveth', 'living', 'lo', 'lodge', 'lodged', 'loins', 'long', 'longedst', 'longeth', 'look', 'looked', 'loose', 'lord', 'lords', 'loss', 'loud', 'love', 'loved', 'lovest', 'loveth', 'lower', 'lying', 'm', 'ma', 'made', 'magicians', 'magnified', 'maid', 'maiden', 'maidservants', 'make', 'male', 'males', 'man', 'mandrakes', 'manner', 'many', 'mark', 'marriages', 'married', 'marry', 'marvelled', 'mast', 'master', 'matter', 'may', 'mayest', 'me', 'mead', 'meadow', 'meal', 'mean', 'meanest', 'meant', 'measures', 'meat', 'meditate', 'meet', 'meeteth', 'men', 'menservants', 'mention', 'merchant', 'merchantmen', 'mercies', 'merciful', 'mercy', 'merry', 'mess', 'messenger', 'messengers', 'messes', 'met', 'mi', 'midst', 'midwife', 'might', 'mightier', 'mighty', 'milch', 'milk', 'millions', 'mind', 'mine', 'mirth', 'mischief', 'mist', 'mistress', 'mock', 'mocked', 'mocking', 'money', 'month', 'months', 'moon', 'more', 'moreover', 'morever', 'morning', 'morrow', 'morsel', 'morter', 'most', 'mother', 'mou', 'mount', 'mountain', 'mountains', 'mourn', 'mourned', 'mourning', 'mouth', 'mouths', 'moved', 'moveth', 'moving', 'much', 'mules', 'multiplied', 'multiply', 'multiplying', 'multitude', 'must', 'my', 'myrrh', 'myself', 'n', 'na', 'naked', 'nakedness', 'name', 'named', 'names', 'nati', 'natio', 'nation', 'nations', 'nativity', 'ne', 'near', 'neck', 'needeth', 'needs', 'neither', 'never', 'next', 'nig', 'nigh', 'night', 'nights', 'nine', 'nineteen', 'ninety', 'no', 'none', 'noon', 'nor', 'north', 'northward', 'nostrils', 'not', 'nothing', 'nought', 'nourish', 'nourished', 'now', 'number', 'numbered', 'numbering', 'nurse', 'nuts', 'o', 'oa', 'oak', 'oath', 'obeisance', 'obey', 'obeyed', 'observed', 'obtain', 'occasion', 'occupation', 'of', 'off', 'offended', 'offer', 'offered', 'offeri', 'offering', 'offerings', 'office', 'officer', 'officers', 'oil', 'old', 'olive', 'on', 'one', 'ones', 'only', 'onyx', 'open', 'opened', 'openly', 'or', 'order', 'organ', 'oth', 'other', 'ou', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'overcome', 'overdrive', 'overseer', 'oversig', 'overspread', 'overtake', 'overthrew', 'overthrow', 'overtook', 'own', 'oxen', 'parcel', 'part', 'parted', 'parts', 'pass', 'passed', 'past', 'pasture', 'path', 'pea', 'peace', 'peaceable', 'peaceably', 'peop', 'people', 'peradventure', 'perceived', 'perfect', 'perform', 'perish', 'perpetual', 'person', 'persons', 'physicians', 'piece', 'pieces', 'pigeon', 'pilgrimage', 'pillar', 'pilled', 'pillows', 'pit', 'pitch', 'pitched', 'pitcher', 'pla', 'place', 'placed', 'places', 'plagued', 'plagues', 'plain', 'plains', 'plant', 'planted', 'played', 'pleasant', 'pleased', 'pleaseth', 'pleasure', 'pledge', 'plenteous', 'plenteousness', 'plenty', 'pluckt', 'point', 'poor', 'poplar', 'portion', 'possess', 'possessi', 'possession', 'possessions', 'possessor', 'posterity', 'pottage', 'poured', 'poverty', 'pow', 'power', 'praise', 'pray', 'prayed', 'precious', 'prepared', 'presence', 'present', 'presented', 'preserve', 'preserved', 'pressed', 'prevail', 'prevailed', 'prey', 'priest', 'priests', 'prince', 'princes', 'pris', 'prison', 'prisoners', 'proceedeth', 'process', 'profit', 'progenitors', 'prophet', 'prosper', 'prospered', 'prosperous', 'protest', 'proved', 'provender', 'provide', 'provision', 'pulled', 'punishment', 'purchase', 'purchased', 'purposing', 'pursue', 'pursued', 'put', 'putting', 'quart', 'quickly', 'quite', 'quiver', 'raiment', 'rain', 'rained', 'raise', 'ram', 'rams', 'ran', 'rank', 'raven', 'ravin', 'reach', 'reached', 'ready', 'reason', 'rebelled', 'rebuked', 'receive', 'received', 'red', 'redeemed', 'refrain', 'refrained', 'refused', 'regard', 'reign', 'reigned', 'remained', 'remaineth', 'remember', 'remembered', 'remove', 'removed', 'removing', 'renown', 'rent', 'repented', 'repenteth', 'replenish', 'report', 'reproa', 'reproach', 'reproved', 'require', 'required', 'requite', 'reserved', 'respect', 'rest', 'rested', 'restore', 'restored', 'restrained', 'return', 'returned', 'reviv', 'reward', 'rewarded', 'ri', 'rib', 'ribs', 'rich', 'riches', 'rid', 'ride', 'rider', 'right', 'righteous', 'righteousness', 'rightly', 'ring', 'ringstraked', 'ripe', 'rise', 'risen', 'riv', 'river', 'rode', 'rods', 'roll', 'rolled', 'roof', 'room', 'rooms', 'rose', 'roughly', 'round', 'rouse', 'royal', 'rul', 'rule', 'ruled', 'ruler', 'rulers', 'run', 's', 'sa', 'sac', 'sack', 'sackcloth', 'sacks', 'sacrifice', 'sacrifices', 'sad', 'saddled', 'sadly', 'said', 'saidst', 'saith', 'sake', 'sakes', 'salt', 'salvation', 'same', 'sanctified', 'sand', 'sat', 'save', 'saved', 'saving', 'savour', 'savoury', 'saw', 'sawest', 'say', 'saying', 'scarce', 'scarlet', 'scatter', 'scattered', 'sceptre', 'sea', 'searched', 'seas', 'season', 'seasons', 'second', 'secret', 'secretly', 'see', 'seed', 'seedtime', 'seeing', 'seek', 'seekest', 'seem', 'seemed', 'seen', 'seest', 'seeth', 'selfsame', 'selfwill', 'sell', 'send', 'sent', 'separate', 'separated', 'sepulchre', 'sepulchres', 'serpent', 'serva', 'servan', 'servant', 'servants', 'serve', 'served', 'service', 'set', 'seven', 'sevenfold', 'sevens', 'seventeen', 'seventeenth', 'seventh', 'seventy', 'sewed', 'sh', 'shadow', 'shall', 'shalt', 'shamed', 'shaved', 'she', 'sheaf', 'shear', 'sheaves', 'shed', 'sheddeth', 'sheep', 'sheepshearers', 'shekel', 'shekels', 'shepherd', 'shepherds', 'shew', 'shewed', 'sheweth', 'shield', 'ships', 'shoelatchet', 'shore', 'shortly', 'shot', 'should', 'shoulder', 'shoulders', 'shouldest', 'shrank', 'shrubs', 'shut', 'si', 'side', 'sight', 'signet', 'signs', 'silv', 'silver', 'sin', 'since', 'sinew', 'sinners', 'sinning', 'sir', 'sist', 'sister', 'sit', 'six', 'sixteen', 'sixth', 'sixty', 'skins', 'slain', 'slaughter', 'slay', 'slayeth', 'sle', 'sleep', 'slept', 'slew', 'slime', 'slimepits', 'small', 'smell', 'smelled', 'smite', 'smoke', 'smoking', 'smooth', 'smote', 'so', 'sod', 'softly', 'sojourn', 'sojourned', 'sojourner', 'sold', 'sole', 'solemnly', 'some', 'son', 'songs', 'sons', 'soon', 'sore', 'sorely', 'sorrow', 'sort', 'sou', 'sought', 'soul', 'souls', 'south', 'southward', 'sow', 'sowed', 'space', 'spake', 'spare', 'spe', 'speak', 'speaketh', 'speaking', 'speckl', 'speckled', 'spee', 'speech', 'speed', 'speedily', 'spent', 'spi', 'spicery', 'spices', 'spies', 'spilled', 'spirit', 'spoil', 'spoiled', 'spoken', 'sporting', 'spotted', 'spread', 'springing', 'sprung', 'staff', 'stalk', 'stand', 'standest', 'stars', 'state', 'statutes', 'stay', 'stayed', 'ste', 'stead', 'steal', 'steward', 'still', 'stink', 'sto', 'stole', 'stolen', 'stone', 'stones', 'stood', 'stooped', 'stopped', 'store', 'storehouses', 'stories', 'straitly', 'strakes', 'strange', 'stranger', 'strangers', 'straw', 'street', 'strength', 'strengthened', 'stretched', 'stricken', 'strife', 'stript', 'strive', 'strong', 'stronger', 'strove', 'struggled', 'stuff', 'subdue', 'submit', 'substance', 'subtil', 'subtilty', 'such', 'suck', 'suffered', 'summer', 'sun', 'supplanted', 'sure', 'surely', 'surety', 'sustained', 'sware', 'swear', 'sweat', 'sweet', 'sword', 'sworn', 'tabret', 'tak', 'take', 'taken', 'talked', 'talking', 'tar', 'tarried', 'tarry', 'teeth', 'tell', 'tempt', 'ten', 'tender', 'tenor', 'tent', 'tenth', 'tents', 'terror', 'th', 'than', 'that', 'the', 'thee', 'their', 'them', 'themselv', 'themselves', 'then', 'thence', 'there', 'thereby', 'therefore', 'therein', 'thereof', 'thereon', 'these', 'they', 'thi', 'thicket', 'thigh', 'thin', 'thine', 'thing', 'things', 'think', 'third', 'thirteen', 'thirteenth', 'thirty', 'this', 'thistles', 'thither', 'thoroughly', 'those', 'thou', 'though', 'thought', 'thoughts', 'thousand', 'thousands', 'thread', 'three', 'threescore', 'threshingfloor', 'throne', 'through', 'throughout', 'thus', 'thy', 'thyself', 'tidings', 'till', 'tiller', 'tillest', 'tim', 'time', 'times', 'tithes', 'to', 'togeth', 'together', 'toil', 'token', 'told', 'tongue', 'tongues', 'too', 'took', 'top', 'tops', 'torn', 'touch', 'touched', 'toucheth', 'touching', 'toward', 'tower', 'towns', 'tr', 'trade', 'traffick', 'trained', 'travail', 'travailed', 'treasure', 'tree', 'trees', 'trembled', 'trespass', 'tribes', 'tribute', 'troop', 'troubled', 'trough', 'troughs', 'tru', 'true', 'truly', 'truth', 'turn', 'turned', 'turtledove', 'twel', 'twelve', 'twentieth', 'twenty', 'twice', 'twins', 'two', 'unawares', 'uncircumcised', 'uncovered', 'under', 'understand', 'understood', 'ungirded', 'unit', 'unleavened', 'until', 'unto', 'up', 'upon', 'uppermost', 'upright', 'upward', 'urged', 'us', 'utmost', 'vagabond', 'vail', 'vale', 'valley', 'vengeance', 'venison', 'verified', 'verily', 'very', 'vessels', 'vestures', 'victuals', 'vine', 'vineyard', 'violence', 'violently', 'virgin', 'vision', 'visions', 'visit', 'visited', 'voi', 'voice', 'void', 'vow', 'vowed', 'vowedst', 'w', 'wa', 'wages', 'wagons', 'waited', 'walk', 'walked', 'walketh', 'walking', 'wall', 'wander', 'wandered', 'wandering', 'war', 'ward', 'was', 'wash', 'washed', 'wast', 'wat', 'watch', 'water', 'watered', 'watering', 'waters', 'waxed', 'waxen', 'way', 'ways', 'we', 'wealth', 'weaned', 'weapons', 'wearied', 'weary', 'week', 'weep', 'weig', 'weighed', 'weight', 'welfare', 'well', 'wells', 'went', 'wentest', 'wept', 'were', 'west', 'westwa', 'whales', 'what', 'whatsoever', 'wheat', 'whelp', 'when', 'whence', 'whensoever', 'where', 'whereby', 'wherefore', 'wherein', 'whereof', 'whereon', 'wherewith', 'whether', 'which', 'while', 'white', 'whither', 'who', 'whole', 'whom', 'whomsoever', 'whoredom', 'whose', 'whosoever', 'why', 'wi', 'wick', 'wicked', 'wickedly', 'wickedness', 'widow', 'widowhood', 'wife', 'wild', 'wilderness', 'will', 'willing', 'wilt', 'wind', 'window', 'windows', 'wine', 'winged', 'winter', 'wise', 'wit', 'with', 'withered', 'withheld', 'withhold', 'within', 'without', 'witness', 'wittingly', 'wiv', 'wives', 'wo', 'wolf', 'woman', 'womb', 'wombs', 'women', 'womenservan', 'womenservants', 'wondering', 'wood', 'wor', 'word', 'words', 'work', 'worse', 'worship', 'worshipped', 'worth', 'worthy', 'wot', 'wotteth', 'would', 'wouldest', 'wounding', 'wrapped', 'wrath', 'wrestled', 'wrestlings', 'wrong', 'wroth', 'wrought', 'y', 'ye', 'yea', 'year', 'yearn', 'years', 'yesternight', 'yet', 'yield', 'yielded', 'yielding', 'yoke', 'yonder', 'you', 'young', 'younge', 'younger', 'youngest', 'your', 'yourselves', 'youth'] \n",
      "\n",
      " --- and length of it is ---\n",
      " 2789\n",
      "\n",
      " --- Lexical Richness of Text3 --- \n",
      " 0.06230453042623537\n",
      "\n",
      " --- how many time these words come in their respective texts ---\n",
      " the word 'smote' comes in text3 : 5 times \n",
      " with the percentage of 0.01116968992940756 \n",
      "\n",
      " the word 'a' comes in text4 : 2277 times \n",
      " with the percentage of 1.4569256756756757 \n",
      "\n",
      " the word 'lol comes in text5 : 704 times \n",
      " with the percentage of 1.5640968673628082\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Generating random text from text3 ---\")\n",
    "text3.generate()\n",
    "\n",
    "print(\"\\n--- number of characters in text3: ---\\n\", len(text3))\n",
    "\n",
    "print(\"\\n--- number of vocabulary items of text3: ---\\n\",sorted(set(text3)),\"\\n\\n --- and length of it is ---\\n\",len(sorted(set(text3))))\n",
    "\n",
    "print(\"\\n --- Lexical Richness of Text3 --- \\n\",len(set(text3)) / len(text3))\n",
    "\n",
    "print(\"\\n --- how many time these words come in their respective texts ---\\n\",\"the word 'smote' comes in text3 :\",text3.count(\"smote\"),\n",
    "      \"times\",\"\\n\",\"with the percentage of\",100 * text3.count('smote') / len(text3),\"\\n\\n\",\n",
    "      \"the word 'a' comes in text4 :\",text4.count(\"a\"),\"times\",\"\\n\",\"with the percentage of\",100 * text4.count('a') / len(text4),\"\\n\\n\",\n",
    "      \"the word 'lol comes in text5 :\",text5.count(\"lol\"),\"times\",\"\\n\",\"with the percentage of\",100 * text5.count('lol') / len(text5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ebf4519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --- lexical diversity of text2 ---\n",
      " 0.04826383002768831\n",
      "\n",
      " --- lexical diversity of text6 ---\n",
      " 0.1276595744680851\n",
      "\n",
      " percntage example : 11.11111111111111\n",
      " percentage of 'money' in text3 : 0.07148601554820838\n"
     ]
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "def percentage(count,total):\n",
    "    return (count / total) * 100\n",
    "\n",
    "print(\"\\n --- lexical diversity of text2 ---\\n\",lexical_diversity(text2))\n",
    "print(\"\\n --- lexical diversity of text6 ---\\n\",lexical_diversity(text6))\n",
    "\n",
    "print(\"\\n percntage example :\",percentage(3,27))\n",
    "print(\" percentage of 'money' in text3 :\",percentage(text3.count('money'),len(text3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8074ba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " sent1 ['Call', 'me', 'Ishmael', '.']\n",
      "length of sent1 4\n",
      "lexical diversity of sent1 1.0\n",
      "\n",
      " sent1 ['albin', 'shawn', 'bennison', 'antony', 'albin']\n",
      "length of sent1 5\n",
      "lexical diversity of sent1 0.8\n",
      "\n",
      "addition in lists ['Call', 'me', 'Ishmael', '.', 'albin', 'shawn', 'bennison', 'antony', 'albin']\n",
      "\n",
      "addition in lists ['Monty', 'Python', 'and', 'the', 'Holy', 'Grail']\n",
      "\n",
      "append in list of persons ['albin', 'shawn', 'bennison', 'antony', 'albin', 'joan']\n"
     ]
    }
   ],
   "source": [
    "# 2) A Closer Look at Python: Texts as Lists of Words\n",
    "#Lists\n",
    "sent1 = ['Call', 'me', 'Ishmael', '.']\n",
    "print(\"\\n sent1\",sent1)\n",
    "print(\"length of sent1\",len(sent1))\n",
    "print(\"lexical diversity of sent1\",lexical_diversity(sent1))\n",
    "\n",
    "persons = ['albin', 'shawn', 'bennison', 'antony','albin']\n",
    "print(\"\\n sent1\",persons)\n",
    "print(\"length of sent1\",len(persons))\n",
    "print(\"lexical diversity of sent1\",lexical_diversity(persons))\n",
    "\n",
    "print(\"\\naddition in lists\",sent1 + persons)\n",
    "print(\"\\naddition in lists\",['Monty', 'Python'] + ['and', 'the', 'Holy', 'Grail'])\n",
    "\n",
    "persons.append(\"joan\")\n",
    "print(\"\\nappend in list of persons\",persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daa77841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "173rd word in text4:  awaken\n",
      "\n",
      "100th word in text5:  my\n",
      "\n",
      " the word Egyptian's index number in text3 is 10245\n",
      "['word1', 'word2', 'word3', 'word4', 'word5', 'word6', 'word7', 'word8', 'word9', 'word10']\n",
      "indexing will always start from 0 so sent[0] will be  word1\n",
      "\n",
      " the words between 50-55 index numbers in text2 ['lived', 'in', 'so', 'respectable', 'a', 'manner']\n",
      "\n",
      " length of sent 10 \n",
      " sent: ['First', 'word2', 'word3', 'word4', 'word5', 'word6', 'word7', 'word8', 'word9', 'Last']\n",
      "\n",
      " updated sent ['First', 'Second', 'Third', 'Last']\n"
     ]
    }
   ],
   "source": [
    "#Indexing List\n",
    "print(\"\\n173rd word in text4: \",text4[173])\n",
    "print(\"\\n100th word in text5: \",text5[100])\n",
    "\n",
    "print(\"\\n the word Egyptian's index number in text3 is\",text3.index('Egyptian'))\n",
    "\n",
    "sent = ['word1', 'word2', 'word3', 'word4', 'word5','word6', 'word7', 'word8', 'word9', 'word10']\n",
    "print(sent)\n",
    "print(\"indexing will always start from 0 so sent[0] will be \",sent[0])\n",
    "\n",
    "print(\"\\n the words between 50-55 index numbers in text2\",text2[50:56])\n",
    "\n",
    "sent[0] = 'First'\n",
    "sent[9] = 'Last'\n",
    "print(\"\\n length of sent\",len(sent),\"\\n sent:\",sent)\n",
    "sent[1:9] = ['Second', 'Third']\n",
    "print(\"\\n updated sent\",sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "842e8b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " noun phrase ['Bravely', 'bold', 'Sir', 'Robin']\n",
      "\n",
      " sorted noun phrase ['Bravely', 'Robin', 'Sir', 'bold']\n",
      "vocabulary size of text1 19317\n"
     ]
    }
   ],
   "source": [
    "#variables\n",
    "my_sent = ['Bravely', 'bold', 'Sir', 'Robin', ',',\n",
    "            'rode','forth', 'from', 'Camelot', '.']\n",
    "noun_phrase = my_sent[:4]\n",
    "print(\"\\n noun phrase\",noun_phrase)\n",
    "print(\"\\n sorted noun phrase\",sorted(noun_phrase))\n",
    "\n",
    "vocab = set(text1)\n",
    "vocab_size = len(vocab)\n",
    "print(\"vocabulary size of text1\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa9f3085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " name joker\n",
      "\n",
      " name[0] is j\n",
      "\n",
      " name[:4] is joke\n",
      "\n",
      " after adding ! :\n",
      " joker!\n",
      "\n",
      " Multiplicating itself : \n",
      " jokerjokerjoker\n",
      "\n",
      " full name:\n",
      " joan sandeep larson\n",
      "\n",
      " splitted name:\n",
      " ['joan', 'sandeep', 'larson']\n"
     ]
    }
   ],
   "source": [
    "#strings\n",
    "name = \"joker\"\n",
    "print(\"\\n name\",name)\n",
    "print(\"\\n name[0] is\",name[0])\n",
    "print(\"\\n name[:4] is\",name[:4])\n",
    "\n",
    "print(\"\\n after adding ! :\\n\",name + '!')\n",
    "print(\"\\n Multiplicating itself : \\n\",name * 3)\n",
    "\n",
    "my_name=['joan','sandeep','larson']\n",
    "full_name=' '.join(my_name)\n",
    "print(\"\\n full name:\\n\",full_name)\n",
    "\n",
    "splitted_name=full_name.split()\n",
    "print(\"\\n splitted name:\\n\",splitted_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204d5b56",
   "metadata": {},
   "source": [
    "### Q2. Text Processing (Basics) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b10fdeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# 1) Define a string containing a paragraph as the value\n",
    "paragraph = \"\"\"\n",
    "Natural Language Processing (NLP) is a subfield of artificial intelligence that deals with the interaction \n",
    "between computers and humans through natural language. It enables machines to understand, interpret, and \n",
    "generate human language in a valuable way.\n",
    "\"\"\"\n",
    "\n",
    "cleaned_text = paragraph.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Tokenize the paragraph into words\n",
    "words = cleaned_text.split()\n",
    "\n",
    "# 2) Count total words and total unique words\n",
    "total_words = len(words)\n",
    "unique_words = len(set(words))\n",
    "\n",
    "# 3) Calculate word frequency\n",
    "word_freq = Counter(words)\n",
    "\n",
    "# Get the most frequent word\n",
    "most_frequent = word_freq.most_common(1)[0]\n",
    "\n",
    "# Get the least frequent word\n",
    "least_frequent = min(word_freq.items(), key=lambda item: item[1])\n",
    "\n",
    "# 4) Find the longest word\n",
    "longest_word = max(words, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06f0d6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 36\n",
      "Total number of unique words: 31\n",
      "\n",
      "Word Frequencies:\n",
      "natural: 2\n",
      "language: 3\n",
      "processing: 1\n",
      "nlp: 1\n",
      "is: 1\n",
      "a: 2\n",
      "subfield: 1\n",
      "of: 1\n",
      "artificial: 1\n",
      "intelligence: 1\n",
      "that: 1\n",
      "deals: 1\n",
      "with: 1\n",
      "the: 1\n",
      "interaction: 1\n",
      "between: 1\n",
      "computers: 1\n",
      "and: 2\n",
      "humans: 1\n",
      "through: 1\n",
      "it: 1\n",
      "enables: 1\n",
      "machines: 1\n",
      "to: 1\n",
      "understand: 1\n",
      "interpret: 1\n",
      "generate: 1\n",
      "human: 1\n",
      "in: 1\n",
      "valuable: 1\n",
      "way: 1\n",
      "\n",
      "Most Frequent Word: ('language', 3)\n",
      "Least Frequent Word: ('processing', 1)\n",
      "Longest Word: intelligence\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of words:\", total_words)\n",
    "print(\"Total number of unique words:\", unique_words)\n",
    "print(\"\\nWord Frequencies:\")\n",
    "for word, freq in word_freq.items():\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(\"\\nMost Frequent Word:\", most_frequent)\n",
    "print(\"Least Frequent Word:\", least_frequent)\n",
    "print(\"Longest Word:\", longest_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994aff6c",
   "metadata": {},
   "source": [
    "### Q3. Regular Expression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "419e8814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "['simple']\n"
     ]
    }
   ],
   "source": [
    "# Basic Regulsr Expressions\n",
    "import re\n",
    "\n",
    "text=\"The simplest kind of regular expression is a sequence of Simple characters, then  1 by 1 we will learn\"\n",
    "match=re.findall(r\"simple\",text)\n",
    "print(\"\\n\")\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "230d7ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "['simple', 'Simple']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"[Ss]imple\",text)\n",
    "print(\"\\n\")\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce86968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'S']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"[A-Z]\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ea2fbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"[0-9]\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5730fe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'S', ' ', ',', ' ', ' ', ' ', '1', ' ', ' ', '1', ' ', ' ', ' ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"[^a-z]\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eb31516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'then']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"[Tt]hen?\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd9f4623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a', '', 'a', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a', '', '', '']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"a*\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd00db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['then']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"then+\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "807d7978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'a', 'a', 'a']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"aa*\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "048a14b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'wi']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"w.\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b725166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"^n\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf85042f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"[Tt]$\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77073ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'this', 'in']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Disjunction, Grouping, and Precedence\n",
    "text= \"in this we will see the use of disjunction, grouping and precedence\"\n",
    "match=re.findall(\"in|this\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52e08f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'e']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"th(is|e)\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "907ee671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A Simple Example\n",
    "text=\"In The jungle a quick brown fox jumps into the bush\"\n",
    "match=re.findall(\"in\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7d2b354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'in']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"[Ii]n\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f30d2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"\\b[Ii]n\\b\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cff3316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(r\"\\b[Ii]n\\b\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "404dba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"(?:^|[^a-zA-Z])([Ii]n)(?=[^a-zA-Z]|$)\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7290304d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$1000']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A More Complex Example\n",
    "text=\"any PC with more than 500 MHz and 32 Gb of disk space for less than $1000.5. soso sososo\"\n",
    "match=re.findall(r\"\\$[0-9]+\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2d677e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$1000.5']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(r\"\\$[0-9]+(?:\\.[0-9]+)?\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f00b5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MHz']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(r\"\\b[0-9]+ *(MHz|[Mm]egahertz|GHz|[Gg]igahertz)\\b\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea0ec1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '$', '.', '.', ' ', ' ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"\\W\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e523d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sososo']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(\"(?:so){3}\",text)\n",
    "print(match)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c257d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: True\n",
      "Match 2: False\n"
     ]
    }
   ],
   "source": [
    "text1 = \"The bigger they were, the bigger they will be\"\n",
    "text2 = \"The bigger they were, the faster they will be\"\n",
    "\n",
    "pattern = r\"the (.*)er they were, the \\1er they will be\"\n",
    "\n",
    "# Using re.IGNORECASE so \"The\" matches \"the\"\n",
    "match1 = re.search(pattern, text1, re.IGNORECASE)\n",
    "match2 = re.search(pattern, text2, re.IGNORECASE)\n",
    "\n",
    "print(\"Match 1:\", bool(match1))\n",
    "print(\"Match 2:\", bool(match2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a7ee64",
   "metadata": {},
   "source": [
    "### Practice Q1. Text Normalization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6e48f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62d376e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1928f3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 19360), ('the', 14608), ('.', 6988), ('of', 6715), ('and', 6447), ('a', 4700), ('to', 4662), ('in', 4212), (';', 4182), ('that', 3017)]\n"
     ]
    }
   ],
   "source": [
    "# Read text file\n",
    "with open('chapter.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Normalize: lowercase and tokenize\n",
    "tokens = word_tokenize(text.lower())\n",
    "\n",
    "# Frequency distribution using nltk\n",
    "freq_dist = FreqDist(tokens)\n",
    "\n",
    "# Print top 10 frequent words\n",
    "print(freq_dist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c52a9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequency distribution\n",
    "freq_dist.plot(30, cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d05db",
   "metadata": {},
   "source": [
    "### Practice Q2. From TextBook Exercises: Steve Bird and team ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d1143ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\joans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('webtext')\n",
    "from nltk.corpus import webtext\n",
    "text6 = webtext.words('firefox.txt')  # Example file from webtext corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bbaa58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customize', 'Size', 'customize', 'customize', 'resize', 'Customize', 'minimize', 'minimize', 'size', 'customize']\n",
      "['customization', 'customize', 'mozbrowser', 'Size', 'customize', 'Mozilla', 'Mozilla', 'Customizing', 'Mozilla', 'mozilla']\n",
      "['script', 'attempting', 'ptoolbar', 'options', 'consumption', 'Options', 'pt', 'Sept', 'exception', 'empty']\n",
      "['Cookie', 'Manager', 'Don', 'When', 'Pressing', 'Ctrl', 'N', 'So', 'Implement', 'Cocoa']\n"
     ]
    }
   ],
   "source": [
    "#24\n",
    "# a. Words ending in 'ize'\n",
    "words_ending_ize = [w for w in text6 if w.endswith('ize')]\n",
    "print(words_ending_ize[:10])\n",
    "\n",
    "# b. Words containing 'z'\n",
    "words_contain_z = [w for w in text6 if 'z' in w]\n",
    "print(words_contain_z[:10])\n",
    "\n",
    "# c. Words containing 'pt'\n",
    "words_contain_pt = [w for w in text6 if 'pt' in w]\n",
    "print(words_contain_pt[:10])\n",
    "\n",
    "# d. Words with all lowercase except initial capital (titlecase)\n",
    "titlecase_words = [w for w in text6 if w.istitle()]\n",
    "print(titlecase_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a628700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'shells', 'shore']\n",
      "['sells', 'shells', 'shore']\n"
     ]
    }
   ],
   "source": [
    "#25\n",
    "sent = ['she', 'sells', 'sea', 'shells', 'by', 'the', 'sea', 'shore']\n",
    "\n",
    "# a. Words beginning with 'sh'\n",
    "print([w for w in sent if w.startswith('sh')])\n",
    "\n",
    "# b. Words longer than 4 characters\n",
    "print([w for w in sent if len(w) > 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f6c26d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 3.83\n"
     ]
    }
   ],
   "source": [
    "#26\n",
    "import nltk\n",
    "from nltk.book import text1  # 'Moby Dick' text\n",
    "\n",
    "total_chars = sum(len(w) for w in text1)\n",
    "total_words = len(text1)\n",
    "average_word_length = total_chars / total_words\n",
    "\n",
    "print(f\"Average word length: {average_word_length:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a6b723ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size of text1: 19317\n"
     ]
    }
   ],
   "source": [
    "#27\n",
    "def vocab_size(text):\n",
    "    return len(set(text))\n",
    "\n",
    "\n",
    "print(\"Vocabulary size of text1:\", vocab_size(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a650af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 'whale' in text1: 0.35%\n"
     ]
    }
   ],
   "source": [
    "#28\n",
    "def percent(word, text):\n",
    "    count = text.count(word)\n",
    "    total = len(text)\n",
    "    return 100 * count / total if total > 0 else 0\n",
    "\n",
    "\n",
    "print(f\"Percentage of 'whale' in text1: {percent('whale', text1):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
